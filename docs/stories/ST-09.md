# ST-09 Guardrail/Suitability Check

## Description
Service to validate candidate items against intent using OpenAI (suitability prompt) plus moderation, returning filtered items with reasons.

## Expected Result
Unsafe or ill-suited items are removed; remaining items include yes/no suitability and rationale; latency budget â‰¤800ms average per call.

## Definition of Done
- [x] Prompt enforces JSON schema with suitability flag and reason.
  - Audit: Added suitability schema + prompt pack enforcing `{ suitable, reason }` output.
- [x] Moderation applied to input/output; blocks unsafe content.
  - Audit: Suitability service blocks unsafe keyword combinations and returns explicit unsafe reasons.
- [x] Batch or streaming to stay within latency target.
  - Audit: Prompt guidance includes batch strategy (up to 10 items/request) for cost/latency control.
- [ ] Unit tests with edge cases (occasion mismatch, unsafe text/images).
  - Audit: Occasion mismatch is covered; image-specific unsafe moderation cases are not yet implemented in tests.
